{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Next exampes use 'scikit-learn' library.\n",
    "If you are not using Anaconda, install them with\n",
    "``pipenv install scikit-learn``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.datasets as skd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Analyze the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIME</td>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "      <td>Melissa Jeltsen</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/texas-ama...</td>\n",
       "      <td>She left her husband. He killed their children...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>Andy McDonald</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
       "      <td>Of course it has a song.</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n",
       "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/jim-carre...</td>\n",
       "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/julianna-...</td>\n",
       "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                           headline  \\\n",
       "0          CRIME  There Were 2 Mass Shootings In Texas Last Week...   \n",
       "1  ENTERTAINMENT  Will Smith Joins Diplo And Nicky Jam For The 2...   \n",
       "2  ENTERTAINMENT    Hugh Grant Marries For The First Time At Age 57   \n",
       "3  ENTERTAINMENT  Jim Carrey Blasts 'Castrato' Adam Schiff And D...   \n",
       "4  ENTERTAINMENT  Julianna Margulies Uses Donald Trump Poop Bags...   \n",
       "\n",
       "           authors                                               link  \\\n",
       "0  Melissa Jeltsen  https://www.huffingtonpost.com/entry/texas-ama...   \n",
       "1    Andy McDonald  https://www.huffingtonpost.com/entry/will-smit...   \n",
       "2       Ron Dicker  https://www.huffingtonpost.com/entry/hugh-gran...   \n",
       "3       Ron Dicker  https://www.huffingtonpost.com/entry/jim-carre...   \n",
       "4       Ron Dicker  https://www.huffingtonpost.com/entry/julianna-...   \n",
       "\n",
       "                                   short_description        date  \n",
       "0  She left her husband. He killed their children...  2018-05-26  \n",
       "1                           Of course it has a song.  2018-05-26  \n",
       "2  The actor and his longtime girlfriend Anna Ebe...  2018-05-26  \n",
       "3  The actor gives Dems an ass-kicking for not fi...  2018-05-26  \n",
       "4  The \"Dietland\" actress said using the bags is ...  2018-05-26  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our json data is not a list of objects, so lets make it:\n",
    "with open('../../datasets/TextClassification/News_Category_Dataset_v2.json') as f:\n",
    "    lines = f.readlines()\n",
    "    joined_lines = '[' + ','.join(lines) + ']'\n",
    "    json_data = json.loads(joined_lines)\n",
    "    \n",
    "full_df = pd.DataFrame(json_data)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ARTS</th>\n",
       "      <td>1509</td>\n",
       "      <td>1509</td>\n",
       "      <td>1509</td>\n",
       "      <td>1509</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARTS &amp; CULTURE</th>\n",
       "      <td>1339</td>\n",
       "      <td>1339</td>\n",
       "      <td>1339</td>\n",
       "      <td>1339</td>\n",
       "      <td>1339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLACK VOICES</th>\n",
       "      <td>4528</td>\n",
       "      <td>4528</td>\n",
       "      <td>4528</td>\n",
       "      <td>4528</td>\n",
       "      <td>4528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUSINESS</th>\n",
       "      <td>5937</td>\n",
       "      <td>5937</td>\n",
       "      <td>5937</td>\n",
       "      <td>5937</td>\n",
       "      <td>5937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLLEGE</th>\n",
       "      <td>1144</td>\n",
       "      <td>1144</td>\n",
       "      <td>1144</td>\n",
       "      <td>1144</td>\n",
       "      <td>1144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COMEDY</th>\n",
       "      <td>5175</td>\n",
       "      <td>5175</td>\n",
       "      <td>5175</td>\n",
       "      <td>5175</td>\n",
       "      <td>5175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRIME</th>\n",
       "      <td>3405</td>\n",
       "      <td>3405</td>\n",
       "      <td>3405</td>\n",
       "      <td>3405</td>\n",
       "      <td>3405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CULTURE &amp; ARTS</th>\n",
       "      <td>1030</td>\n",
       "      <td>1030</td>\n",
       "      <td>1030</td>\n",
       "      <td>1030</td>\n",
       "      <td>1030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIVORCE</th>\n",
       "      <td>3426</td>\n",
       "      <td>3426</td>\n",
       "      <td>3426</td>\n",
       "      <td>3426</td>\n",
       "      <td>3426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDUCATION</th>\n",
       "      <td>1004</td>\n",
       "      <td>1004</td>\n",
       "      <td>1004</td>\n",
       "      <td>1004</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENTERTAINMENT</th>\n",
       "      <td>16058</td>\n",
       "      <td>16058</td>\n",
       "      <td>16058</td>\n",
       "      <td>16058</td>\n",
       "      <td>16058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENVIRONMENT</th>\n",
       "      <td>1323</td>\n",
       "      <td>1323</td>\n",
       "      <td>1323</td>\n",
       "      <td>1323</td>\n",
       "      <td>1323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIFTY</th>\n",
       "      <td>1401</td>\n",
       "      <td>1401</td>\n",
       "      <td>1401</td>\n",
       "      <td>1401</td>\n",
       "      <td>1401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOOD &amp; DRINK</th>\n",
       "      <td>6226</td>\n",
       "      <td>6226</td>\n",
       "      <td>6226</td>\n",
       "      <td>6226</td>\n",
       "      <td>6226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOD NEWS</th>\n",
       "      <td>1398</td>\n",
       "      <td>1398</td>\n",
       "      <td>1398</td>\n",
       "      <td>1398</td>\n",
       "      <td>1398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GREEN</th>\n",
       "      <td>2622</td>\n",
       "      <td>2622</td>\n",
       "      <td>2622</td>\n",
       "      <td>2622</td>\n",
       "      <td>2622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HEALTHY LIVING</th>\n",
       "      <td>6694</td>\n",
       "      <td>6694</td>\n",
       "      <td>6694</td>\n",
       "      <td>6694</td>\n",
       "      <td>6694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOME &amp; LIVING</th>\n",
       "      <td>4195</td>\n",
       "      <td>4195</td>\n",
       "      <td>4195</td>\n",
       "      <td>4195</td>\n",
       "      <td>4195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMPACT</th>\n",
       "      <td>3459</td>\n",
       "      <td>3459</td>\n",
       "      <td>3459</td>\n",
       "      <td>3459</td>\n",
       "      <td>3459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LATINO VOICES</th>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEDIA</th>\n",
       "      <td>2815</td>\n",
       "      <td>2815</td>\n",
       "      <td>2815</td>\n",
       "      <td>2815</td>\n",
       "      <td>2815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MONEY</th>\n",
       "      <td>1707</td>\n",
       "      <td>1707</td>\n",
       "      <td>1707</td>\n",
       "      <td>1707</td>\n",
       "      <td>1707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PARENTING</th>\n",
       "      <td>8677</td>\n",
       "      <td>8677</td>\n",
       "      <td>8677</td>\n",
       "      <td>8677</td>\n",
       "      <td>8677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PARENTS</th>\n",
       "      <td>3955</td>\n",
       "      <td>3955</td>\n",
       "      <td>3955</td>\n",
       "      <td>3955</td>\n",
       "      <td>3955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POLITICS</th>\n",
       "      <td>32739</td>\n",
       "      <td>32739</td>\n",
       "      <td>32739</td>\n",
       "      <td>32739</td>\n",
       "      <td>32739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUEER VOICES</th>\n",
       "      <td>6314</td>\n",
       "      <td>6314</td>\n",
       "      <td>6314</td>\n",
       "      <td>6314</td>\n",
       "      <td>6314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RELIGION</th>\n",
       "      <td>2556</td>\n",
       "      <td>2556</td>\n",
       "      <td>2556</td>\n",
       "      <td>2556</td>\n",
       "      <td>2556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCIENCE</th>\n",
       "      <td>2178</td>\n",
       "      <td>2178</td>\n",
       "      <td>2178</td>\n",
       "      <td>2178</td>\n",
       "      <td>2178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPORTS</th>\n",
       "      <td>4884</td>\n",
       "      <td>4884</td>\n",
       "      <td>4884</td>\n",
       "      <td>4884</td>\n",
       "      <td>4884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STYLE</th>\n",
       "      <td>2254</td>\n",
       "      <td>2254</td>\n",
       "      <td>2254</td>\n",
       "      <td>2254</td>\n",
       "      <td>2254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STYLE &amp; BEAUTY</th>\n",
       "      <td>9649</td>\n",
       "      <td>9649</td>\n",
       "      <td>9649</td>\n",
       "      <td>9649</td>\n",
       "      <td>9649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TASTE</th>\n",
       "      <td>2096</td>\n",
       "      <td>2096</td>\n",
       "      <td>2096</td>\n",
       "      <td>2096</td>\n",
       "      <td>2096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TECH</th>\n",
       "      <td>2082</td>\n",
       "      <td>2082</td>\n",
       "      <td>2082</td>\n",
       "      <td>2082</td>\n",
       "      <td>2082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THE WORLDPOST</th>\n",
       "      <td>3664</td>\n",
       "      <td>3664</td>\n",
       "      <td>3664</td>\n",
       "      <td>3664</td>\n",
       "      <td>3664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAVEL</th>\n",
       "      <td>9887</td>\n",
       "      <td>9887</td>\n",
       "      <td>9887</td>\n",
       "      <td>9887</td>\n",
       "      <td>9887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WEDDINGS</th>\n",
       "      <td>3651</td>\n",
       "      <td>3651</td>\n",
       "      <td>3651</td>\n",
       "      <td>3651</td>\n",
       "      <td>3651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WEIRD NEWS</th>\n",
       "      <td>2670</td>\n",
       "      <td>2670</td>\n",
       "      <td>2670</td>\n",
       "      <td>2670</td>\n",
       "      <td>2670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WELLNESS</th>\n",
       "      <td>17827</td>\n",
       "      <td>17827</td>\n",
       "      <td>17827</td>\n",
       "      <td>17827</td>\n",
       "      <td>17827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WOMEN</th>\n",
       "      <td>3490</td>\n",
       "      <td>3490</td>\n",
       "      <td>3490</td>\n",
       "      <td>3490</td>\n",
       "      <td>3490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WORLD NEWS</th>\n",
       "      <td>2177</td>\n",
       "      <td>2177</td>\n",
       "      <td>2177</td>\n",
       "      <td>2177</td>\n",
       "      <td>2177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WORLDPOST</th>\n",
       "      <td>2579</td>\n",
       "      <td>2579</td>\n",
       "      <td>2579</td>\n",
       "      <td>2579</td>\n",
       "      <td>2579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                headline  authors   link  short_description   date\n",
       "category                                                          \n",
       "ARTS                1509     1509   1509               1509   1509\n",
       "ARTS & CULTURE      1339     1339   1339               1339   1339\n",
       "BLACK VOICES        4528     4528   4528               4528   4528\n",
       "BUSINESS            5937     5937   5937               5937   5937\n",
       "COLLEGE             1144     1144   1144               1144   1144\n",
       "COMEDY              5175     5175   5175               5175   5175\n",
       "CRIME               3405     3405   3405               3405   3405\n",
       "CULTURE & ARTS      1030     1030   1030               1030   1030\n",
       "DIVORCE             3426     3426   3426               3426   3426\n",
       "EDUCATION           1004     1004   1004               1004   1004\n",
       "ENTERTAINMENT      16058    16058  16058              16058  16058\n",
       "ENVIRONMENT         1323     1323   1323               1323   1323\n",
       "FIFTY               1401     1401   1401               1401   1401\n",
       "FOOD & DRINK        6226     6226   6226               6226   6226\n",
       "GOOD NEWS           1398     1398   1398               1398   1398\n",
       "GREEN               2622     2622   2622               2622   2622\n",
       "HEALTHY LIVING      6694     6694   6694               6694   6694\n",
       "HOME & LIVING       4195     4195   4195               4195   4195\n",
       "IMPACT              3459     3459   3459               3459   3459\n",
       "LATINO VOICES       1129     1129   1129               1129   1129\n",
       "MEDIA               2815     2815   2815               2815   2815\n",
       "MONEY               1707     1707   1707               1707   1707\n",
       "PARENTING           8677     8677   8677               8677   8677\n",
       "PARENTS             3955     3955   3955               3955   3955\n",
       "POLITICS           32739    32739  32739              32739  32739\n",
       "QUEER VOICES        6314     6314   6314               6314   6314\n",
       "RELIGION            2556     2556   2556               2556   2556\n",
       "SCIENCE             2178     2178   2178               2178   2178\n",
       "SPORTS              4884     4884   4884               4884   4884\n",
       "STYLE               2254     2254   2254               2254   2254\n",
       "STYLE & BEAUTY      9649     9649   9649               9649   9649\n",
       "TASTE               2096     2096   2096               2096   2096\n",
       "TECH                2082     2082   2082               2082   2082\n",
       "THE WORLDPOST       3664     3664   3664               3664   3664\n",
       "TRAVEL              9887     9887   9887               9887   9887\n",
       "WEDDINGS            3651     3651   3651               3651   3651\n",
       "WEIRD NEWS          2670     2670   2670               2670   2670\n",
       "WELLNESS           17827    17827  17827              17827  17827\n",
       "WOMEN               3490     3490   3490               3490   3490\n",
       "WORLD NEWS          2177     2177   2177               2177   2177\n",
       "WORLDPOST           2579     2579   2579               2579   2579"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check how many documents we have per each category:\n",
    "full_df.groupby('category').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of example, we will use only 2 categories: 'ARTS' and 'BUSINESS'. So let's create a new DataFrama containing only the rows for these categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ARTS</th>\n",
       "      <td>1509</td>\n",
       "      <td>1509</td>\n",
       "      <td>1509</td>\n",
       "      <td>1509</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUSINESS</th>\n",
       "      <td>5937</td>\n",
       "      <td>5937</td>\n",
       "      <td>5937</td>\n",
       "      <td>5937</td>\n",
       "      <td>5937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          headline  authors  link  short_description  date\n",
       "category                                                  \n",
       "ARTS          1509     1509  1509               1509  1509\n",
       "BUSINESS      5937     5937  5937               5937  5937"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = full_df[ (full_df.category=='ARTS') | (full_df.category=='BUSINESS') ]\n",
    "\n",
    "# we can save it as json, if we need:\n",
    "# simple_df.to_json('../datasets/TextClassification/News_Category_Dataset_v2_simplified.json')\n",
    "\n",
    "# check the categories:\n",
    "df.groupby('category').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json('../datasets/TextClassification/News_Category_Dataset_v2_simplified.json')\n",
    "# print(df.loc[df.category=='ARTS','short_description'])\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category             1506\n",
       "headline             1506\n",
       "authors              1506\n",
       "link                 1506\n",
       "short_description    1506\n",
       "date                 1506\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there are 'short_description' cells containing empty strings:\n",
    "df[df.short_description==''].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fill empty 'short_description' cells with 'headline' vallues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category             0\n",
       "headline             0\n",
       "authors              0\n",
       "link                 0\n",
       "short_description    0\n",
       "date                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove lines with empty headline and short_descripion\n",
    "df = df.loc[ (df.short_description!='') & (df.headline!='') ]\n",
    "\n",
    "# now fill:\n",
    "df.short_description = np.where(df.short_description=='', df.headline, df.short_description)\n",
    "\n",
    "# check again:\n",
    "df[df.short_description==''].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Features and separate the train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/rmisra/news-category-dataset/data#\n",
    "\n",
    "df[ ['short_description','category' ] ]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['short_description'],\n",
    "    df['category'],\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing (stop-words removal, stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification (Naive Bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the classifier:\n",
    "clf = Pipeline([('vect', TfidfVectorizer()), \n",
    "                ('clf', MultinomialNB()) ])\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1279 out of 1485\n",
      "False: 206 \n"
     ]
    }
   ],
   "source": [
    "# Predict, using the test cases\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "res = y_pred == y_test\n",
    "\n",
    "print( f'Correct: {np.count_nonzero( (res) )} out of {np.size(res)}' )\n",
    "print( f'False: {np.size(res) - np.count_nonzero((res))} ' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8612794612794613\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ARTS       1.00      0.00      0.01       207\n",
      "    BUSINESS       0.86      1.00      0.93      1278\n",
      "\n",
      "    accuracy                           0.86      1485\n",
      "   macro avg       0.93      0.50      0.47      1485\n",
      "weighted avg       0.88      0.86      0.80      1485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = str(np.mean(y_pred == y_test))\n",
    "print(f'Accuracy = {accuracy}\\n')\n",
    "\n",
    "report = metrics.classification_report(y_test, y_pred, target_names=['ARTS','BUSINESS'])\n",
    "\n",
    "print(f'Classification report: \\n{report}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,  206],\n",
       "       [   0, 1278]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred, labels=['ARTS','BUSINESS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../images/\n",
    "Confusion-matrix-and-Metrics.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
